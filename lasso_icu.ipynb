{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80d2262-3805-479e-9d6c-98b8fa6815b3",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77373d35-4812-427e-bede-4af3c2bcae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d0ee22-5fac-4909-a17e-ffe3f9c5a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7638c-42c8-461c-ab1a-bb68ce620f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install dcurves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37bbf21-b02c-48af-9e36-9ab88f146d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cbd3e6-ccc3-41d2-893b-38f9522e04f3",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef9a84-04cc-4f26-8f96-78639ff80cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd # Load and manipulate data and for one-hot encoding\n",
    "import numpy as np # Calculate the mean and standard deviation\n",
    "import re # used for regular expressions\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer  # Multiple imputation\n",
    "from sklearn.preprocessing import StandardScaler # Data normalization\n",
    "from sklearn.linear_model import LogisticRegression # For categorical variables in multiple imputation\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV # Cross validation for tuning hyperparameters\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, brier_score_loss # For scoring during model evaluation\n",
    "from sklearn.calibration import calibration_curve # Calibration plot\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess # Enable LOESS smoothing\n",
    "import shap # Import SHAP library\n",
    "import matplotlib.pyplot as plt\n",
    "# To enable the display of the resulting plot in the interface itself\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be98db-1943-42bf-b494-4a3b2b7e6bf5",
   "metadata": {},
   "source": [
    "# Functions defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b24031-646a-4708-81e4-a8bd17fdf979",
   "metadata": {},
   "source": [
    "## Functions to perform winsorization on data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295dadf-af72-45ac-9ab3-313153e1e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform winsorization on multiple series in a data frame\n",
    "def winso_df(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    '''\n",
    "    Perform winsorization on selected columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df: pd.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    columns: list\n",
    "        List of column names to be winsorized.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        DataFrame with winsorized columns.\n",
    "    '''  \n",
    "    for column in columns:\n",
    "        df[column] = winso(df[column])  # Apply winsorization only to non-NaN values\n",
    "    return df\n",
    "\n",
    "# Function to perform winsorization on one series\n",
    "def winso(x: pd.Series, xmin: float = None, xmax: float = None) -> pd.Series:\n",
    "    '''\n",
    "    Perform winsorization on a single Series, excluding NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    x: pd.Series\n",
    "        A Series of data to be winsorized.\n",
    "    xmin: float, optional\n",
    "        Minimum allowable value, if not provided, defaults to 1st percentile.\n",
    "    xmax: float, optional\n",
    "        Maximum allowable value, if not provided, defaults to 99th percentile.\n",
    "    \n",
    "    Returns:\n",
    "    pd.Series\n",
    "        Winsorized Series, with NaNs untouched.\n",
    "    '''\n",
    "    # Perform winsorization only on non-NaN values\n",
    "    non_nan_mask = ~x.isna()  # Mask for non-NaN values\n",
    "    \n",
    "    if xmin is None:\n",
    "        xmin = np.quantile(x[non_nan_mask], 0.01)  # Use non-NaN values to calculate percentiles\n",
    "    if xmax is None:\n",
    "        xmax = np.quantile(x[non_nan_mask], 0.99)\n",
    "    \n",
    "    # Apply winsorization only to the non-NaN values\n",
    "    x[non_nan_mask] = np.where(x[non_nan_mask] > xmax, xmax, x[non_nan_mask])\n",
    "    x[non_nan_mask] = np.where(x[non_nan_mask] < xmin, xmin, x[non_nan_mask])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a523b32-9b26-402f-83bb-1ffc2c9b9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    # Function to perform winsorization on multiple series in a data frame\n",
    "    def winso_df(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "        '''\n",
    "        Perform winsorization on selected columns in a DataFrame.\n",
    "    \n",
    "        Parameters:\n",
    "        df: pd.DataFrame\n",
    "            The DataFrame containing the data.\n",
    "        columns: list\n",
    "            List of column names to be winsorized.\n",
    "        Returns:\n",
    "        pd.DataFrame\n",
    "            DataFrame with winsorized columns.\n",
    "        '''    \n",
    "        df_copy = df.copy()  # Make a copy of the DataFrame to avoid modifying it in place\n",
    "        for column in columns:\n",
    "            df_copy[column] = winso(df_copy[column])\n",
    "        return df_copy\n",
    "    \n",
    "    # Function to perform winsorization on one series\n",
    "    def winso(x: pd.Series, xmin: float = None, xmax: float = None) -> pd.Series:\n",
    "        '''\n",
    "        Perform winsorization on a single Series.\n",
    "        \n",
    "        Parameters:\n",
    "        x: pd.Series\n",
    "            A Series of data to be winsorized.\n",
    "        xmin: float, optional\n",
    "            Minimum allowable value, if not provided, defaults to 1st percentile.\n",
    "        xmax: float, optional\n",
    "            Maximum allowable value, if not provided, defaults to 99th percentile.\n",
    "        \n",
    "        Returns:\n",
    "        pd.Series\n",
    "            Winsorized Series.\n",
    "        '''\n",
    "        if xmin is None:\n",
    "            xmin = np.quantile(x, 0.5)\n",
    "        if xmax is None:\n",
    "            xmax = np.quantile(x, 0.5)\n",
    "        \n",
    "        x = np.where(x > xmax, xmax, x)\n",
    "        x = np.where(x < xmin, xmin, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a1b8d-145e-461b-aba3-2c1628096c8b",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fff68e-4d68-4ebe-aa09-be8f20443d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'T:\\Projects\\NAPKON\\projects\\CROSS_mortality\\python\\original_20240909.csv', sep = ';', decimal = ',')\n",
    "df\n",
    "\n",
    "# df.head(5)\n",
    "# df.dtypes; # ';' prevents the output from being displayed\n",
    "# df.describe(); # Focus on numerical variables only, excluding NaN (Not a Number) values.\n",
    "# df.describe(include = 'all'); # Provide full summary statistics\n",
    "# df.info() # Concise summary of the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558ac70-fef0-494e-a832-30615d1bf509",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a503f3-6a61-42bb-baa3-daa868329871",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f33f58-347a-4a83-b091-5e5d7a0bd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b6e1a5-4202-4eb7-bab6-e0e90fe1726d",
   "metadata": {},
   "source": [
    "## Remove unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae4241-70d4-49e6-9695-aabec1ed307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df = df.drop(['Unnamed: 0', 'psn', 'comor_chronic_lung_no_asthma'], axis = 1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91941b87-7048-45e4-88e1-a5067d1dc8db",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b803b-f5fe-47f3-b647-4c606d9c6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference level will not be removed \n",
    "df = pd.get_dummies(df, columns = ['sex'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c0179-0049-4aaa-8d39-3209e8f94f4c",
   "metadata": {},
   "source": [
    "## Create the variable 'Deterioration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9a381-c569-42c3-b08b-34e33b0fbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deterioration'] = np.where((df['icu_7d'] == 1) | (df['death_30d'] == 1), 1, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ce68f-207b-4a82-830d-b29b78852ed0",
   "metadata": {},
   "source": [
    "## Descriptive statistics for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98705c2f-6185-48cb-9ba8-1fc3f67b755e",
   "metadata": {},
   "source": [
    "### All patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a3f93-fa39-470d-b5a3-f29980791aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n",
    "categorical_cols = ['sex_female', 'sex_male', 'o2_supplement', 'impaired_consciousness', 'obesity', 'comor_cvd', 'comor_chronic_lung', 'comor_ckd', 'comor_chronic_liver', 'icu_7d', 'death_30d', 'deterioration']\n",
    "\n",
    "df_categoricals = df[categorical_cols]\n",
    "\n",
    "#df_categoricals.apply(lambda x: (x == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9783696-e5d0-4949-95ed-fb3d9302249a",
   "metadata": {},
   "source": [
    "### Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba43ea-0dce-4f1f-8ce4-7881bc2aad83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_outcomes = ['icu_7d', 'death_30d', 'deterioration']\n",
    "\n",
    "for outcome in df_outcomes:\n",
    "    filtered_df = df_categoricals[df_categoricals[outcome] == 1]\n",
    "    print(f'The current outcome is : {outcome}')\n",
    "    \n",
    "    for column in filtered_df.columns:\n",
    "        print(filtered_df[column].value_counts())\n",
    "        print(filtered_df[column].value_counts() / filtered_df[column].count())\n",
    "        print(filtered_df[column].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e9cfc-1abf-4c83-a561-f3085e846ac6",
   "metadata": {},
   "source": [
    "## Descriptive statistics for continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e07bd-5cc2-4a45-a112-d6a62628d1a3",
   "metadata": {},
   "source": [
    "### All patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de13c7-7ac5-4498-bbd6-5956c7bf29c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9826ca-f26c-425e-be3b-20e4948d4b8f",
   "metadata": {},
   "source": [
    "### Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cddd58f-6079-41ad-92f7-05d7c932e7f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_outcomes = ['icu_7d', 'death_30d', 'deterioration']\n",
    "\n",
    "for outcome in df_outcomes:\n",
    "    filtered_df = df_categoricals[df_categoricals[outcome] == 1]\n",
    "    print(f'The current outcome is : {outcome}')\n",
    "    print(filtered_df.describe())\n",
    "    print(filtered_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab7e9e-2779-4d21-8648-0ef9283ab2a8",
   "metadata": {},
   "source": [
    "# Split data into training and test sets (by center locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca3b28-bdc6-4fb0-93cc-4a079ca6bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of north cities\n",
    "north_cities = ['Hamburg', 'Berlin', 'Hannover', 'Dashti', 'Duisburg', 'Greifswald', 'Essen', \n",
    "                'Dortmund', 'Oldenburg', 'Flensburg', 'Bielefeld', 'Kiel', 'Magdeburg', \n",
    "                'Bochum', 'Düsseldorf', 'Göttingen', 'Münster', 'Aachen', 'Leipzig']\n",
    "\n",
    "# Filter rows where ptcenter matches any of the north cities\n",
    "df_north = df[df['ptcenter'].str.contains('|'.join(north_cities), na=False, flags=re.IGNORECASE)]\n",
    "\n",
    "# Filter rows where ptcenter does not match any of the north cities\n",
    "df_south = df[~df['ptcenter'].str.contains('|'.join(north_cities), na=False, flags=re.IGNORECASE)]\n",
    "\n",
    "# Rename the datasets for development and validation cohorts\n",
    "dev_df = df_north  # development cohort\n",
    "eval_df = df_south  # validation cohort\n",
    "\n",
    "dev_df = dev_df.drop(['ptcenter'], axis = 1)\n",
    "eval_df = eval_df.drop(['ptcenter'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2497ff-cf85-4f2c-9f9f-0d0608d46685",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae2ef3-9946-4607-bcb9-f2b63abd9171",
   "metadata": {},
   "source": [
    "## Remove variables missing >= 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455716b8-4b42-4fce-bf91-36bc20d83aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage = dev_df.isna().mean()  # Get percentage of missing values per column\n",
    "columns_to_drop = missing_percentage[missing_percentage >= 0.4].index  # Get column names with > 40% missing\n",
    "dev_df = dev_df.drop(columns = columns_to_drop, axis=1)  # Drop those columns (axis=1 for columns)\n",
    "\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509202d4-ecec-4578-af51-de850312ea8c",
   "metadata": {},
   "source": [
    "## Remove outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafa936-b161-43d3-96e5-e6e058ceaf2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using percentiles:\n",
    " \n",
    "numerical_cols_winso = ['hr', 'bp_sys', 'bp_dia', 'rr', 'temp', 'spo2', 'wbc_abs', 'platelet_abs', 'urea', 'creatinine', 'crp', 'ldh']\n",
    "\n",
    "dev_df = winso_df(dev_df, numerical_cols_winso)\n",
    "\n",
    "dev_df_cleaned = dev_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23b5aa-d88c-4f42-9e90-837168500366",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    # Using IQR to detect outliers\n",
    "    \n",
    "    numerical_cols_iqr = ['hr', 'bp_sys', 'bp_dia', 'rr', 'temp', 'spo2', 'wbc_abs', 'platelet_abs', 'urea', 'creatinine', 'crp', 'ldh']\n",
    "    \n",
    "    # Loop through each numerical column and remove outliers\n",
    "    for col in numerical_cols_iqr:\n",
    "        # Calculate Q1 (25th percentile) and Q3 (75th percentile) for each column\n",
    "        Q1 = dev_df[col].quantile(0.25)\n",
    "        Q3 = dev_df[col].quantile(0.75)\n",
    "        \n",
    "        # Compute IQR for each column\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define outlier boundaries for each column\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Filter out outliers from the current column\n",
    "        dev_df_cleaned = dev_df[(dev_df[col] >= lower_bound) & (dev_df[col] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53237a8d-fbc8-44f3-a147-71e83823c7ba",
   "metadata": {},
   "source": [
    "## Multiple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56518040-9286-4303-bbaa-e2c09bb5f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target columns\n",
    "dev_df_cleaned.drop(['death_30d', 'deterioration'], axis=1, inplace=True)\n",
    "\n",
    "# Define number of imputations and iterations\n",
    "n_imputations = 10\n",
    "max_iter = 10\n",
    "\n",
    "# Initialize an empty list to hold all imputed datasets\n",
    "imputed_dev_df = []\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_cols = ['age', 'num_comor', 'hr', 'bp_sys', 'bp_dia', 'rr', 'temp', 'spo2', 'wbc_abs', 'platelet_abs', 'urea', 'creatinine', 'crp', 'ldh']\n",
    "categorical_cols_icu = [col for col in categorical_cols if col not in ['death_30d', 'deterioration']]\n",
    "\n",
    "# Initialize IterativeImputer for continuous variables with PMM\n",
    "pmm_imputer = IterativeImputer(max_iter=max_iter, random_state=123)\n",
    "\n",
    "# Initialize IterativeImputer for categorical variables with logistic regression\n",
    "logreg_imputer = IterativeImputer(max_iter=max_iter, estimator=LogisticRegression(max_iter=1000), random_state=123)\n",
    "\n",
    "# Perform multiple imputations for continuous variables\n",
    "for i in range(n_imputations):\n",
    "    # Fit and transform the continuous data\n",
    "    imputed_numerical = pmm_imputer.fit_transform(dev_df_cleaned[numerical_cols])\n",
    "    imputed_categorical = logreg_imputer.fit_transform(dev_df_cleaned[categorical_cols_icu])\n",
    "    \n",
    "    # Convert to DataFrame and store\n",
    "    imputed_numerical_df = pd.DataFrame(imputed_numerical, columns=numerical_cols)\n",
    "    imputed_categorical_df = pd.DataFrame(imputed_categorical, columns=categorical_cols_icu)\n",
    "    \n",
    "    # Combine the imputed numerical and categorical DataFrames\n",
    "    combined_imputed_df = pd.concat([imputed_numerical_df, imputed_categorical_df], axis=1)\n",
    "    \n",
    "    # Append the combined DataFrame to the list\n",
    "    imputed_dev_df.append(combined_imputed_df)\n",
    "\n",
    "# Stack all imputed datasets into one DataFrame\n",
    "combined_imputed_dev_df = pd.concat(imputed_dev_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9122db8-226a-487a-99fa-bb18989d935d",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a386862-c6ae-4524-ad88-7ca4acaa3f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_cols = ['age', 'num_comor', 'hr', 'bp_sys', 'bp_dia', 'rr', 'temp', 'spo2', 'wbc_abs', 'platelet_abs', 'urea', 'creatinine', 'crp', 'ldh']\n",
    "categorical_cols_icu = [col for col in categorical_cols if col not in ['death_30d', 'deterioration']]\n",
    "\n",
    "# Initialize the StandardScaler for numeric data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numeric columns\n",
    "scaled_numeric_data = scaler.fit_transform(combined_imputed_dev_df[numerical_cols])\n",
    "\n",
    "# Convert the scaled numeric data back to a DataFrame\n",
    "scaled_numeric_dev_df = pd.DataFrame(scaled_numeric_data, columns = numerical_cols)\n",
    "\n",
    "# Recombine the standardized numeric columns with the original unchanged categorical columns\n",
    "standardized_dev_df = pd.concat([scaled_numeric_dev_df.reset_index(drop=True), \n",
    "                             combined_imputed_dev_df[categorical_cols_icu].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the standardized DataFrame\n",
    "print(standardized_dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9b175-f7c6-4778-b68f-fd9737196fd3",
   "metadata": {},
   "source": [
    "## Split the development dataset into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937b1d2-acd8-4c33-a636-307c60275a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_icu = standardized_dev_df.drop(['icu_7d'], axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225faab0-cc2a-47dd-8f9b-70e774e7fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_icu = standardized_dev_df['icu_7d'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5ed71-8d2c-4a1c-9bee-fdbfce03323a",
   "metadata": {},
   "source": [
    "## Train the model (before feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aec562-8441-4b26-9f88-a7b80c109339",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1.0, 10.0]}  # 'C' is the inverse of regularization strength\n",
    "\n",
    "if True:\n",
    "        # Custom scoring function that combines AUC and Calibration Intercept\n",
    "    def custom_auc_calibration_intercept(y_true, y_pred_proba):\n",
    "        # Calculate AUC\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        \n",
    "        # Calculate Calibration Intercept\n",
    "        # Fit a logistic regression model to calculate intercept\n",
    "        log_reg = LogisticRegression(penalty='none', solver='newton-cg').fit(y_pred_proba.reshape(-1, 1), y_true)\n",
    "        calibration_intercept = log_reg.intercept_[0]\n",
    "        \n",
    "        # Combine AUC and Calibration Intercept into a custom score\n",
    "        # Here we subtract the absolute intercept for better calibration\n",
    "        return 0.25 * auc - 0.75 * abs(calibration_intercept)\n",
    "    \n",
    "    # Create custom scorer\n",
    "    custom_scorer = make_scorer(custom_auc_calibration_intercept, greater_is_better=True, needs_proba=True)\n",
    "    \n",
    "# Initialize Lasso logistic regression (L1 penalty)\n",
    "if 'class_weight' in globals():  # Check if class_weight exists\n",
    "    lasso_icu = LogisticRegression(penalty='l1', solver='saga', max_iter=5000, class_weight=class_weight)\n",
    "else:\n",
    "    lasso_icu = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)    \n",
    "\n",
    "# Using the custom scorer in GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lasso_icu, \n",
    "                           param_grid=param_grid, \n",
    "                           #scoring = 'neg_brier_score',\n",
    "                           #scoring = 'neg_log_loss',\n",
    "                           #scoring='roc_auc',  # Use the custom scorer\n",
    "                           scoring = custom_scorer,\n",
    "                           cv=5, \n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV to the data\n",
    "grid_search.fit(X_icu, y_icu)\n",
    "\n",
    "# Now you can access the best estimator after fitting\n",
    "best_lasso_icu = grid_search.best_estimator_\n",
    "\n",
    "# Extract feature importance from the best model (coefficients for Lasso)\n",
    "importances = best_lasso_icu.coef_.flatten()\n",
    "feature_names = X_icu.columns\n",
    "\n",
    "# Create a DataFrame to store feature importances and their names\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort by absolute importance and keep only the top 12 features\n",
    "top_12_features_fscore_icu = importance_df.reindex(importance_df['importance'].abs().sort_values(ascending=False).index).head(12)['feature'].tolist()\n",
    "\n",
    "print(\"Top 12 important features: \", top_12_features_fscore_icu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecde0b1-a239-475f-81fe-867a16938f18",
   "metadata": {},
   "source": [
    "## Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd553d-9a9c-48ad-9a96-fa324126d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_icu_pred_proba = best_lasso_icu.predict_proba(X_icu)[:, 1] \n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_icu, y_icu_pred_proba, n_bins=10)\n",
    "\n",
    "# Apply LOESS smoothing\n",
    "loess_fraction = 0.8  # Adjust this value to change the degree of smoothing\n",
    "smoothed_values = lowess(prob_true, prob_pred, frac=loess_fraction)\n",
    "\n",
    "# Extract smoothed x and y values\n",
    "smoothed_x = smoothed_values[:, 0]\n",
    "smoothed_y = smoothed_values[:, 1]\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve', color='blue')\n",
    "plt.plot(smoothed_x, smoothed_y, label = 'LOESS Smoothed', color = 'red', linewidth = 0.8)\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\", color = 'grey', linewidth = 0.8)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef5bc4-d66c-4cc7-9625-ad5df6cd221f",
   "metadata": {},
   "source": [
    "## SHAP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7a1ac-67a9-4ea6-a957-b28360b4d72d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming best_lasso_icu and X_icu are already defined\n",
    "explainer_icu = shap.Explainer(best_lasso_icu.predict_proba, X_icu)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values_icu = explainer_icu(X_icu)\n",
    "\n",
    "# Extract SHAP values for the positive class (class 1)\n",
    "shap_values_class_1 = shap_values_icu[..., 1]  # For binary classification\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values_class_1, X_icu, show=False, max_display=23)\n",
    "\n",
    "# Calculate mean absolute SHAP values for feature importance\n",
    "mean_shap_values_icu = pd.DataFrame(list(zip(feature_names, abs(shap_values_class_1.values).mean(axis=0))), \n",
    "                                    columns=['feature', 'mean_shap_value_icu'])\n",
    "mean_shap_values_icu = mean_shap_values_icu.sort_values(by='mean_shap_value_icu', ascending=False)\n",
    "\n",
    "print(\"Mean SHAP values for features:\\n\", mean_shap_values_icu)\n",
    "\n",
    "# Plotting mean SHAP values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=mean_shap_values_icu, x='mean_shap_value_icu', y='feature', palette='viridis')\n",
    "plt.title('Mean SHAP Values for Features')\n",
    "plt.xlabel('Mean SHAP Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Extract the top 12 features based on mean SHAP values\n",
    "top_12_features_shap_icu = mean_shap_values_icu['feature'].head(12).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd861d35-efde-435f-bb21-db844251e2ca",
   "metadata": {},
   "source": [
    "## Train the model(after feature selection by SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83f43e-508b-4e35-ac80-49e53be88d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_icu = top_12_features_shap_icu\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1.0, 10.0]}  # 'C' is the inverse of regularization strength\n",
    "\n",
    "if True:\n",
    "        # Custom scoring function that combines AUC and Calibration Intercept\n",
    "    def custom_auc_calibration_intercept(y_true, y_pred_proba):\n",
    "        # Calculate AUC\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        \n",
    "        # Calculate Calibration Intercept\n",
    "        # Fit a logistic regression model to calculate intercept\n",
    "        log_reg = LogisticRegression(penalty='none', solver='newton-cg').fit(y_pred_proba.reshape(-1, 1), y_true)\n",
    "        calibration_intercept = log_reg.intercept_[0]\n",
    "        \n",
    "        # Combine AUC and Calibration Intercept into a custom score\n",
    "        # Here we subtract the absolute intercept for better calibration\n",
    "        return 0.25 * auc - 0.75 * abs(calibration_intercept)\n",
    "    \n",
    "    # Create custom scorer\n",
    "    custom_scorer = make_scorer(custom_auc_calibration_intercept, greater_is_better=True, needs_proba=True)\n",
    "        \n",
    "# Initialize Lasso logistic regression (L1 penalty)\n",
    "if 'class_weight' in globals():  # Check if class_weight exists\n",
    "    lasso_icu = LogisticRegression(penalty='l1', solver='saga', max_iter=5000, class_weight=class_weight)\n",
    "else:\n",
    "    lasso_icu = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)    \n",
    "\n",
    "# Using the custom scorer in GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lasso_icu, \n",
    "                           param_grid=param_grid, \n",
    "                           #scoring = 'neg_brier_score',\n",
    "                           #scoring = 'neg_log_loss',\n",
    "                           #scoring='roc_auc',  # Use the custom scorer\n",
    "                           scoring = custom_scorer,\n",
    "                           cv=5, \n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "X_icu1 = X_icu[selected_features_icu]\n",
    "\n",
    "# Fit GridSearchCV to the data\n",
    "grid_search.fit(X_icu1, y_icu)\n",
    "\n",
    "# Now you can access the best estimator after fitting\n",
    "best_lasso_icu = grid_search.best_estimator_\n",
    "\n",
    "# Extract feature importance from the best model (coefficients for Lasso)\n",
    "importances = best_lasso_icu.coef_.flatten()\n",
    "feature_names = X_icu1.columns\n",
    "\n",
    "# Create a DataFrame to store feature importances and their names\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort by absolute importance and keep only the top 12 features\n",
    "top_12_features_fscore_icu = importance_df.reindex(importance_df['importance'].abs().sort_values(ascending=False).index).head(12)['feature'].tolist()\n",
    "\n",
    "print(\"Top 12 important features: \", top_12_features_fscore_icu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365876a7-af02-4a07-8996-3cec30561c75",
   "metadata": {},
   "source": [
    "## Extract the model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa098a5-bbde-47ce-b4d0-f5e9dc10fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients from the best Lasso model\n",
    "coefficients = best_lasso_icu.coef_.flatten()  # Flatten to get a 1D array\n",
    "feature_names = X_icu1.columns  # Get the feature names from the training data\n",
    "\n",
    "# Create a DataFrame to display the coefficients with their corresponding features\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by the absolute value of the coefficients for easier interpretation\n",
    "coefficients_df = coefficients_df.reindex(coefficients_df['coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Display the coefficients\n",
    "print(coefficients_df)\n",
    "\n",
    "# Save the coefficients for later use if needed\n",
    "coefficients_df.to_csv('lasso_coefficients.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d234a9-cf0b-485e-b513-72323f3aa55c",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e660144-6222-493b-912e-888778614531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities on the develoment set\n",
    "X_icu = X_icu[selected_features_icu]\n",
    "y_icu_pred_proba = best_lasso_icu.predict_proba(X_icu)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score_icu = roc_auc_score(y_icu, y_icu_pred_proba)\n",
    "\n",
    "print(\"AUC Score: \", auc_score_icu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77824d46-2c57-4e78-96c6-00c5922efb43",
   "metadata": {},
   "source": [
    "## Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c5da8-26b1-48d9-88c9-1728bd015917",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_icu = X_icu[selected_features_icu]\n",
    "\n",
    "y_icu_pred_proba = best_lasso_icu.predict_proba(X_icu)[:, 1] \n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_icu, y_icu_pred_proba, n_bins = 10)\n",
    "\n",
    "# Apply LOESS smoothing\n",
    "loess_fraction = 0.8  # Adjust this value to change the degree of smoothing\n",
    "smoothed_values = lowess(prob_true, prob_pred, frac=loess_fraction)\n",
    "\n",
    "# Extract smoothed x and y values\n",
    "smoothed_x = smoothed_values[:, 0]\n",
    "smoothed_y = smoothed_values[:, 1]\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve', color='blue')\n",
    "plt.plot(smoothed_x, smoothed_y, label = 'LOESS Smoothed', color = 'red', linewidth = 0.8)\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\", color = 'grey', linewidth = 0.8)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512d18b-227d-43b0-b633-2623f43a8644",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98c2b2-3573-4df3-b180-2b77ac863b2c",
   "metadata": {},
   "source": [
    "## Remove variable with missingness >= 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5b726-a01d-480f-8b24-62f747e8ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage = eval_df.isna().mean()\n",
    "cols_to_drop = missing_percentage[missing_percentage >= 0.4].index\n",
    "eval_df = eval_df.drop(cols_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79302b9-9338-4b47-9700-cc721f7a6bdd",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f5c90-7c14-4c2d-b824-ecb160aa2bbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_df = winso_df(eval_df, numerical_cols)\n",
    "\n",
    "eval_df_cleaned = eval_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506c014-193c-4228-b7fa-9499df1bdf59",
   "metadata": {},
   "source": [
    "## Evaluation for ICU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ddbf5-14f6-418d-9864-724ce0b48bcf",
   "metadata": {},
   "source": [
    "### Multiple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18ad09-ea1a-4d92-ac2d-8a771c1acbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target columns\n",
    "eval_df_icu = eval_df_cleaned.drop(['death_30d', 'deterioration'], axis=1)\n",
    "\n",
    "# Define number of imputations and iterations\n",
    "n_imputations = 10\n",
    "max_iter = 10\n",
    "\n",
    "# Initialize an empty list to hold all imputed datasets\n",
    "imputed_eval_df = []\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_cols = ['age', 'num_comor', 'hr', 'bp_sys', 'bp_dia', 'rr', 'temp', 'spo2', 'wbc_abs', 'platelet_abs', 'urea', 'creatinine', 'crp', 'ldh']\n",
    "categorical_cols_icu = [col for col in categorical_cols if col not in ['death_30d', 'deterioration']]\n",
    "\n",
    "# Store the target variable separately\n",
    "target_variable = eval_df_icu['icu_7d'] if 'icu_7d' in eval_df_icu.columns else None\n",
    "\n",
    "# Remove the target variable from categorical columns for imputation\n",
    "if target_variable is not None:\n",
    "    categorical_cols_icu.remove('icu_7d')\n",
    "\n",
    "# Initialize IterativeImputer for continuous variables with PMM\n",
    "pmm_imputer = IterativeImputer(max_iter = max_iter, random_state = 123)\n",
    "\n",
    "# Initialize IterativeImputer for categorical variables with logistic regression\n",
    "logreg_imputer = IterativeImputer(max_iter = max_iter, estimator=LogisticRegression(max_iter = 1000), random_state = 123)\n",
    "\n",
    "# Perform multiple imputations\n",
    "for i in range(n_imputations):\n",
    "    # Fit and transform the continuous data\n",
    "    imputed_numerical = pmm_imputer.fit_transform(eval_df_icu[numerical_cols])\n",
    "    imputed_categorical = logreg_imputer.fit_transform(eval_df_icu[categorical_cols_icu])\n",
    "    \n",
    "    # Convert to DataFrame and store\n",
    "    imputed_numerical_df = pd.DataFrame(imputed_numerical, columns = numerical_cols)\n",
    "    imputed_categorical_df = pd.DataFrame(imputed_categorical, columns = categorical_cols_icu)\n",
    "    \n",
    "    # Combine the imputed numerical and categorical DataFrames\n",
    "    combined_imputed_df = pd.concat([imputed_numerical_df, imputed_categorical_df], axis = 1)\n",
    "    \n",
    "    # If the target variable exists, add it back to the combined DataFrame\n",
    "    if target_variable is not None:\n",
    "        combined_imputed_df['icu_7d'] = target_variable.values\n",
    "    \n",
    "    # Append the combined DataFrame to the list\n",
    "    imputed_eval_df.append(combined_imputed_df)\n",
    "\n",
    "# Stack all imputed datasets into one DataFrame\n",
    "combined_imputed_eval_df = pd.concat(imputed_eval_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53bfe8-d1de-4975-87a3-2b47d3790e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    # Drop the target columns\n",
    "    eval_df_cleaned.drop(['death_30d', 'deterioration'], axis=1, inplace=True)\n",
    "    \n",
    "    # Define number of imputations and iterations\n",
    "    n_imputations = 10\n",
    "    max_iter = 10\n",
    "    \n",
    "    # Initialize an empty list to hold all imputed datasets\n",
    "    imputed_eval_df = []\n",
    "    \n",
    "    # Define numerical and categorical columns\n",
    "    numerical_cols = ['age', 'num_comor', 'hr', 'bp_sys', 'bp_dia', 'rr', 'temp', 'spo2', 'wbc_abs', 'platelet_abs', 'urea', 'creatinine', 'crp', 'ldh']\n",
    "    categorical_cols_icu = [col for col in categorical_cols if col not in ['death_30d', 'deterioration']]\n",
    "    \n",
    "    # Initialize IterativeImputer for continuous variables with PMM\n",
    "    pmm_imputer = IterativeImputer(max_iter=max_iter, random_state=123)\n",
    "    \n",
    "    # Initialize IterativeImputer for categorical variables with logistic regression\n",
    "    logreg_imputer = IterativeImputer(max_iter=max_iter, estimator=LogisticRegression(max_iter=1000), random_state=123)\n",
    "\n",
    "    # Perform multiple imputations for continuous variables\n",
    "    for i in range(n_imputations):\n",
    "        # Fit and transform the continuous data\n",
    "        imputed_numerical = pmm_imputer.fit_transform(eval_df_cleaned[numerical_cols])\n",
    "        imputed_categorical = logreg_imputer.fit_transform(eval_df_cleaned[categorical_cols_icu])\n",
    "        \n",
    "        # Convert to DataFrame and store\n",
    "        imputed_numerical_df = pd.DataFrame(imputed_numerical, columns=numerical_cols)\n",
    "        imputed_categorical_df = pd.DataFrame(imputed_categorical, columns=categorical_cols_icu)\n",
    "        \n",
    "        # Combine the imputed numerical and categorical DataFrames\n",
    "        combined_imputed_df = pd.concat([imputed_numerical_df, imputed_categorical_df], axis=1)\n",
    "        \n",
    "        # Append the combined DataFrame to the list\n",
    "        imputed_eval_df.append(combined_imputed_df)\n",
    "    \n",
    "    # Stack all imputed datasets into one DataFrame\n",
    "    combined_imputed_eval_df = pd.concat(imputed_eval_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac96a8-5556-45c9-933c-f31ff23693c6",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb28d01-b4ee-463f-b1b1-85742803ba6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_cols_icu.append('icu_7d')\n",
    "\n",
    "# Apply the same StandardScaler (already fitted on dev_df) to eval_df\n",
    "scaled_numeric_eval_data = scaler.transform(combined_imputed_eval_df[numerical_cols])\n",
    "\n",
    "# Convert the scaled numeric data back to a DataFrame\n",
    "scaled_numeric_eval_df = pd.DataFrame(scaled_numeric_eval_data, columns = numerical_cols)\n",
    "\n",
    "# Recombine the standardized numeric columns with the original unchanged categorical columns in eval_df\n",
    "standardized_eval_df = pd.concat([scaled_numeric_eval_df.reset_index(drop=True), \n",
    "                                  combined_imputed_eval_df[categorical_cols_icu].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the standardized eval DataFrame\n",
    "print(standardized_eval_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2236c22-8879-41ce-85d9-54661f354832",
   "metadata": {},
   "source": [
    "### Split the eval_df into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02aad9-f922-4bad-949d-1be60439c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_icu = standardized_eval_df.drop(['icu_7d'], axis = 1).copy()  # Features (drop the target column)\n",
    "\n",
    "X_eval_icu = X_eval_icu[selected_features_icu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b951076-76a0-42d5-b368-564f087bac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_icu = standardized_eval_df ['icu_7d'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0c073-0e08-4353-86c9-217523807459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the prevalence in preparation for DCA\n",
    "y_eval_icu = np.array(y_eval_icu)\n",
    "\n",
    "# Calculate the positive rate\n",
    "prevalence = np.mean(y_eval_icu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a476c-82ee-458b-bf11-9785d3ed262f",
   "metadata": {},
   "source": [
    "### AUC computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112af2f5-a6b9-494a-a89a-a3e8c5a7432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities on the validation set\n",
    "y_eval_icu_pred_proba = best_lasso_icu.predict_proba(X_eval_icu)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score_icu = roc_auc_score(y_eval_icu, y_eval_icu_pred_proba)\n",
    "\n",
    "print(\"AUC Score: \", auc_score_icu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975749f4-9d9f-4fba-8d83-54aa3d75b919",
   "metadata": {},
   "source": [
    "### Calibration in the large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e68578-4e7e-41c8-8fde-fc8e520293a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_in_the_large = np.mean(y_eval_icu_pred_proba) - np.mean(y_eval_icu)\n",
    "print(\"Calibration in the Large: \", calibration_in_the_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99186635-d7f4-4b38-870c-725d66c0e785",
   "metadata": {},
   "source": [
    "### Calibration intercept and slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f124c-9323-4db4-aab3-230ebfd086af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_eval_icu is the observed outcome (0 or 1)\n",
    "# and y_eval_icu_pred_proba is the predicted probability from your model\n",
    "\n",
    "# Convert predicted probabilities to log-odds\n",
    "log_odds = np.log(y_eval_icu_pred_proba / (1 - y_eval_icu_pred_proba))\n",
    "\n",
    "# Add a constant term for the intercept in the logistic regression model\n",
    "X_log_odds = sm.add_constant(log_odds)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y_eval_icu, X_log_odds).fit(disp=0)  # disp=0 suppresses output during fitting\n",
    "\n",
    "# Extract the intercept and slope\n",
    "calibration_intercept = model.params[0]  # Intercept\n",
    "calibration_slope = model.params[1]      # Slope\n",
    "\n",
    "print(\"Calibration Intercept: \", calibration_intercept)\n",
    "print(\"Calibration Slope: \", calibration_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd424c-e740-48b4-9260-f8f1ae027644",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    # Predict probabilities on the validation set\n",
    "    y_eval_icu_pred_proba = best_lasso_icu.predict_proba(X_eval_icu)[:, 1]  # Probabilities for the positive class\n",
    "    \n",
    "    # To calculate calibration intercept and slope:\n",
    "    # 1. Take the logit (log-odds) of the predicted probabilities\n",
    "    logit_pred_proba = np.log(y_eval_icu_pred_proba / (1 - y_eval_icu_pred_proba))\n",
    "    \n",
    "    # 2. Reshape and standardize the logit predictions\n",
    "    logit_pred_proba = logit_pred_proba.reshape(-1, 1)\n",
    "    scaler_cali = StandardScaler()\n",
    "    logit_pred_proba_scaled = scaler_cali.fit_transform(logit_pred_proba)\n",
    "    \n",
    "    # 3. Fit a logistic regression model to assess calibration\n",
    "    calibration_model = LogisticRegression(fit_intercept=True)\n",
    "    calibration_model.fit(logit_pred_proba_scaled, y_eval_icu)\n",
    "    \n",
    "    # 4. Extract calibration intercept and slope\n",
    "    calibration_intercept = calibration_model.intercept_[0]\n",
    "    calibration_slope = calibration_model.coef_[0][0]\n",
    "    \n",
    "    print(\"Calibration Intercept: \", calibration_intercept)\n",
    "    print(\"Calibration Slope: \", calibration_slope)\n",
    "    \n",
    "    # Convert intercept back to probability\n",
    "    original_intercept_probability = 1 / (1 + np.exp(-calibration_intercept))\n",
    "    print(\"Calibration Intercept (Probability Scale): \", original_intercept_probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbcab2c-1bbd-4f84-b9b7-2ab585459a75",
   "metadata": {},
   "source": [
    "### Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d339b1-62c0-4093-b778-48c91d495275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_eval_icu, y_eval_icu_pred_proba, n_bins = 100)\n",
    "\n",
    "# Apply LOESS smoothing\n",
    "loess_fraction = 0.8  # Adjust this value to change the degree of smoothing\n",
    "smoothed_values = lowess(prob_true, prob_pred, frac=loess_fraction)\n",
    "\n",
    "# Extract smoothed x and y values\n",
    "smoothed_x = smoothed_values[:, 0]\n",
    "smoothed_y = smoothed_values[:, 1]\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve', color='blue')\n",
    "plt.plot(smoothed_x, smoothed_y, label = 'LOESS Smoothed', color = 'red', linewidth = 0.8)\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\", color = 'grey', linewidth = 0.8)  # Reference line for perfect calibration\n",
    "\n",
    "# Set limits and ensure equal unit lengths on both axes\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable = 'box')  # This ensures equal scaling of both axes\n",
    "\n",
    "plt.xlabel('Predicted risk', fontsize = 14)\n",
    "plt.ylabel('Observed risk', fontsize = 14)\n",
    "plt.xticks(fontsize = 12)  # Adjust font size for x-axis tick labels\n",
    "plt.yticks(fontsize = 12)  # Adjust font size for y-axis tick labels\n",
    "#plt.title('Calibration Plot', fontsize=16)\n",
    "#plt.legend(loc=\"best\", fontsize = 12)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(False)\n",
    "plt.savefig(r'T:\\Projects\\NAPKON\\projects\\CROSS_mortality\\python\\results\\figures\\xgboost_mortality\\calibration_plot_12FeaturesbyFscore.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a1326-bb4e-4a7a-9019-02b6e05152e1",
   "metadata": {},
   "source": [
    "### Brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8cf91e-2861-47dd-b434-5c00b71d9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for the positive class\n",
    "y_eval_icu_pred_proba = best_lasso_icu.predict_proba(X_eval_icu)[:, 1]\n",
    "\n",
    "# Calculate Brier score\n",
    "brier_score = brier_score_loss(y_eval_icu, y_eval_icu_pred_proba)\n",
    "\n",
    "print(f\"Brier Score: {brier_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a808ac8-993a-4877-9edb-dede7ea8f84b",
   "metadata": {},
   "source": [
    "### SHAP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b200c-0815-4afc-918c-a304be25c9c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming best_lasso_icu and X_icu are already defined\n",
    "explainer_icu = shap.Explainer(best_lasso_icu.predict_proba, X_eval_icu)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values_icu = explainer_icu(X_eval_icu)\n",
    "\n",
    "# Extract SHAP values for the positive class (class 1)\n",
    "shap_values_class_1 = shap_values_icu[..., 1]  # For binary classification\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values_class_1, X_eval_icu, show=False, max_display=23)\n",
    "\n",
    "# Calculate mean absolute SHAP values for feature importance\n",
    "mean_shap_values_icu = pd.DataFrame(list(zip(feature_names, abs(shap_values_class_1.values).mean(axis=0))), \n",
    "                                    columns=['feature', 'mean_shap_value_icu'])\n",
    "mean_shap_values_icu = mean_shap_values_icu.sort_values(by='mean_shap_value_icu', ascending=False)\n",
    "\n",
    "print(\"Mean SHAP values for features:\\n\", mean_shap_values_icu)\n",
    "\n",
    "# Plotting mean SHAP values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=mean_shap_values_icu, x='mean_shap_value_icu', y='feature', palette='viridis')\n",
    "plt.title('Mean SHAP Values for Features')\n",
    "plt.xlabel('Mean SHAP Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Extract the top 12 features based on mean SHAP values\n",
    "top_12_features_shap_icu = mean_shap_values_icu['feature'].head(12).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad8ec31-d490-4d91-bba3-6225f05bb127",
   "metadata": {},
   "source": [
    "### LIME analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a35e3-2d7e-4301-b6a1-e77173b89d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LIME explainer\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    training_data=X_eval_icu.values,\n",
    "    feature_names=X_eval_icu.columns,\n",
    "    class_names=['Negative', 'Positive'],  # Modify as needed for binary classes\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Select an instance to explain\n",
    "instance_to_explain = X_eval_icu.iloc[0]\n",
    "\n",
    "# Explain the prediction for the selected instance\n",
    "lime_exp = lime_explainer.explain_instance(\n",
    "    data_row=instance_to_explain,\n",
    "    predict_fn=best_lasso_icu.predict_proba,\n",
    "    num_features=12  # Specify the number of features to display\n",
    ")\n",
    "\n",
    "# Show the explanation\n",
    "lime_exp.show_in_notebook(show_table=True)\n",
    "\n",
    "# Print feature importance for the explained instance\n",
    "print(\"LIME feature importance for the selected instance:\")\n",
    "for feature, importance in lime_exp.as_list():\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2e1b7-cb5d-48f6-89ea-2fbaa8df022d",
   "metadata": {},
   "source": [
    "#### LIME visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35a3e2-f582-452d-8aa7-31e3c8738a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LIME explainer\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    training_data=X_eval_icu.values,\n",
    "    feature_names=X_eval_icu.columns,\n",
    "    class_names=['Negative', 'Positive'],  # Modify as needed for binary classes\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Select an instance to explain\n",
    "instance_to_explain = X_eval_icu.iloc[0]\n",
    "\n",
    "# Explain the prediction for the selected instance\n",
    "lime_exp = lime_explainer.explain_instance(\n",
    "    data_row=instance_to_explain,\n",
    "    predict_fn=best_lasso_icu.predict_proba,\n",
    "    num_features=12  # Specify the number of features to display\n",
    ")\n",
    "\n",
    "# Get the explanation as a list of features and importance values\n",
    "lime_feature_importance = lime_exp.as_list()\n",
    "\n",
    "# Separate features and importance values\n",
    "features, importance = zip(*lime_feature_importance)\n",
    "\n",
    "# Create a pandas DataFrame for easy plotting\n",
    "import pandas as pd\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importance\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')\n",
    "\n",
    "# Customize the background and text colors\n",
    "plt.gca().set_facecolor('white')  # Set background color to white\n",
    "plt.gca().tick_params(axis='y', labelcolor='black')  # Set text color to black\n",
    "plt.gca().tick_params(axis='x', labelcolor='black')  # Set text color to black\n",
    "plt.xlabel('Importance', fontsize=12, color='black')  # Set label color to black\n",
    "plt.ylabel('Feature', fontsize=12, color='black')  # Set label color to black\n",
    "plt.title('LIME Feature Importance', fontsize=14, color='black')  # Set title color to black\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eafeb1-a809-4fb9-8325-139612bb7c5a",
   "metadata": {},
   "source": [
    "### Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64371bb2-53b3-4cdd-937f-7bea13e7caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute permutation importance\n",
    "perm_importance = permutation_importance(\n",
    "    estimator=best_lasso_icu,\n",
    "    X=X_eval_icu,\n",
    "    y=y_eval_icu,\n",
    "    n_repeats=30,\n",
    "    random_state=42,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "# Create a DataFrame to display permutation importances\n",
    "perm_importance_df = pd.DataFrame({\n",
    "    'feature': X_eval_icu.columns,\n",
    "    'importance': perm_importance.importances_mean\n",
    "})\n",
    "\n",
    "# Sort by the mean importance score\n",
    "perm_importance_df = perm_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Print and plot permutation importance\n",
    "print(\"Permutation feature importances:\\n\", perm_importance_df)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=perm_importance_df, x='importance', y='feature', palette='Blues_r')\n",
    "plt.title('Permutation Feature Importances')\n",
    "plt.xlabel('Mean Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Extract the top 12 features based on permutation importance\n",
    "top_12_features_perm_importance = perm_importance_df['feature'].head(12).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431d685-e124-427d-9bdf-aba1e4dbb6f0",
   "metadata": {},
   "source": [
    "### Decision curve analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb81b0-7d1f-4d29-8a4c-63256b52ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `y_eval_icu` (ground truth) and `y_eval_icu_pred_proba` (predicted probabilities) are available\n",
    "dat_all = pd.DataFrame({'icu_7d': y_eval_icu, 'der_pred_cross': y_eval_icu_pred_proba})\n",
    "\n",
    "prevalence = prevalence\n",
    "\n",
    "# Function to calculate net benefit for decision curve analysis\n",
    "def decision_curve_analysis(data, threshold_probs, prevalence = prevalence):\n",
    "    net_benefits = []\n",
    "    for threshold in threshold_probs:\n",
    "        tp = np.sum((data['der_pred_cross'] >= threshold) & (data['icu_7d'] == 1))\n",
    "        fp = np.sum((data['der_pred_cross'] >= threshold) & (data['icu_7d'] == 0))\n",
    "        nb = tp / len(data) - (fp / len(data)) * (threshold / (1 - threshold))\n",
    "        net_benefits.append(nb)\n",
    "    return pd.DataFrame({'threshold': threshold_probs, 'net_benefit': net_benefits})\n",
    "\n",
    "# Function to calculate the net benefit for the \"Treat All\" strategy\n",
    "def treat_all_line(threshold_probs, prevalence):\n",
    "    return prevalence - (1 - prevalence) * (threshold_probs / (1 - threshold_probs))\n",
    "\n",
    "# Define threshold probabilities for DCA\n",
    "threshold_probs = np.linspace(0.01, 1.0, 100)\n",
    "\n",
    "# Perform decision curve analysis\n",
    "df_plot = decision_curve_analysis(dat_all, threshold_probs, prevalence)\n",
    "\n",
    "# Calculate the \"Treat All\" line using the correct formula\n",
    "df_plot['treat_all'] = treat_all_line(threshold_probs, prevalence)\n",
    "\n",
    "# Apply LOESS smoothing to net benefit\n",
    "loess_smoothed = lowess(df_plot['net_benefit'], df_plot['threshold'], frac=0.2)  # frac controls the amount of smoothing\n",
    "\n",
    "# Prepare smoothed results for plotting\n",
    "smoothed_df = pd.DataFrame(loess_smoothed, columns=['threshold', 'smoothed_net_benefit'])\n",
    "\n",
    "# Color and linetype mapping for the plot\n",
    "color_labels = {\n",
    "    'der_pred_cross': '#B22222',  # Red color for CROSS score\n",
    "    'Treat All': '#000000',        # Black color for Treat All\n",
    "    'Treat None': '#808080'        # Grey color for Treat None\n",
    "}\n",
    "linetype_labels = {\n",
    "    'der_pred_cross': 'solid',\n",
    "    'Treat All': 'solid',\n",
    "    'Treat None': 'solid'\n",
    "}\n",
    "legend_labels = {\n",
    "    'der_pred_cross': 'CROSS score',\n",
    "    'Treat All': 'Treat all',\n",
    "    'Treat None': 'Treat none'\n",
    "}\n",
    "\n",
    "# Plot the LOESS smoothed net benefit for CROSS score (DCA curve)\n",
    "sns.lineplot(data=smoothed_df, \n",
    "             x='threshold', \n",
    "             y='smoothed_net_benefit', \n",
    "             label=legend_labels['der_pred_cross'], \n",
    "             color=color_labels['der_pred_cross'], \n",
    "             linestyle=linetype_labels['der_pred_cross'], \n",
    "             linewidth=0.4)  \n",
    "\n",
    "# Plot the Treat None line (always at y = 0)\n",
    "plt.axhline(y=0, \n",
    "            color=color_labels['Treat None'], \n",
    "            linestyle='solid', \n",
    "            label=legend_labels['Treat None'], \n",
    "            linewidth=0.2)  \n",
    "\n",
    "# Plot the Treat All line (calculated as a slant line)\n",
    "sns.lineplot(x=threshold_probs, \n",
    "             y=df_plot['treat_all'], \n",
    "             label=legend_labels['Treat All'], \n",
    "             color=color_labels['Treat All'], \n",
    "             linestyle=linetype_labels['Treat All'], \n",
    "             linewidth=0.2)  \n",
    "\n",
    "# Customize plot\n",
    "plt.title(\"DCA for Multiple Models with LOESS Smoothing\")\n",
    "plt.xlabel(\"Threshold probability\")\n",
    "plt.ylabel(\"Net benefit\")\n",
    "plt.ylim(-0.1, 0.3)  # Adjust y-limits if necessary\n",
    "plt.legend(title=\"Models\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab972c97-e9f4-4f18-894a-a42edbdb100a",
   "metadata": {},
   "source": [
    "## Evaluation for mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5dcf7e-0b22-4665-a7e7-f1ce472c216c",
   "metadata": {},
   "source": [
    "### Multiple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddce34-f7fd-443c-8a5a-59ddeb05a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target columns\n",
    "eval_df_mortality = eval_df_cleaned.drop(['icu_7d', 'deterioration'], axis = 1)\n",
    "\n",
    "# Define number of imputations and iterations\n",
    "n_imputations = 10\n",
    "max_iter = 10\n",
    "\n",
    "# Initialize an empty list to hold all imputed datasets\n",
    "imputed_eval_df = []\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_cols = ['age', 'num_comor', 'hr', 'bp_sys', 'bp_dia', 'rr', 'temp', 'spo2', 'wbc_abs', 'platelet_abs', 'urea', 'creatinine', 'crp', 'ldh']\n",
    "categorical_cols_mortality = [col for col in categorical_cols if col not in ['icu_7d', 'deterioration']]\n",
    "\n",
    "# Store the target variable separately\n",
    "target_variable = eval_df_mortality['death_30d'] if 'death_30d' in eval_df_mortality.columns else None\n",
    "\n",
    "# Remove the target variable from categorical columns for imputation\n",
    "if target_variable is not None:\n",
    "    categorical_cols_mortality.remove('death_30d')\n",
    "\n",
    "# Initialize IterativeImputer for continuous variables with PMM\n",
    "pmm_imputer = IterativeImputer(max_iter=max_iter, random_state=123)\n",
    "\n",
    "# Initialize IterativeImputer for categorical variables with logistic regression\n",
    "logreg_imputer = IterativeImputer(max_iter=max_iter, estimator=LogisticRegression(max_iter=1000), random_state=123)\n",
    "\n",
    "# Perform multiple imputations\n",
    "for i in range(n_imputations):\n",
    "    # Fit and transform the continuous data\n",
    "    imputed_numerical = pmm_imputer.fit_transform(eval_df_mortality[numerical_cols])\n",
    "    imputed_categorical = logreg_imputer.fit_transform(eval_df_mortality[categorical_cols_mortality])\n",
    "    \n",
    "    # Convert to DataFrame and store\n",
    "    imputed_numerical_df = pd.DataFrame(imputed_numerical, columns=numerical_cols)\n",
    "    imputed_categorical_df = pd.DataFrame(imputed_categorical, columns=categorical_cols_mortality)\n",
    "    \n",
    "    # Combine the imputed numerical and categorical DataFrames\n",
    "    combined_imputed_df = pd.concat([imputed_numerical_df, imputed_categorical_df], axis=1)\n",
    "    \n",
    "    # If the target variable exists, add it back to the combined DataFrame\n",
    "    if target_variable is not None:\n",
    "        combined_imputed_df['death_30d'] = target_variable.values\n",
    "    \n",
    "    # Append the combined DataFrame to the list\n",
    "    imputed_eval_df.append(combined_imputed_df)\n",
    "\n",
    "# Stack all imputed datasets into one DataFrame\n",
    "combined_imputed_eval_df = pd.concat(imputed_eval_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054dcd1f-99fc-465d-a999-efbeb9c11ad1",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab58d9-6b45-4308-811d-9d594e83d434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_cols_mortality.append('death_30d')\n",
    "\n",
    "# Apply the same StandardScaler (already fitted on dev_df) to eval_df\n",
    "scaled_numeric_eval_data = scaler.transform(combined_imputed_eval_df[numerical_cols])\n",
    "\n",
    "# Convert the scaled numeric data back to a DataFrame\n",
    "scaled_numeric_eval_df = pd.DataFrame(scaled_numeric_eval_data, columns = numerical_cols)\n",
    "\n",
    "# Recombine the standardized numeric columns with the original unchanged categorical columns in eval_df\n",
    "standardized_eval_df = pd.concat([scaled_numeric_eval_df.reset_index(drop=True), \n",
    "                                  combined_imputed_eval_df[categorical_cols_mortality].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the standardized eval DataFrame\n",
    "print(standardized_eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd4c16-4129-4023-a87c-2deab742fcfe",
   "metadata": {},
   "source": [
    "### Split the eval_df into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198bc11-540f-4c18-bdd5-1feff3f5a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_mortality = standardized_eval_df.drop(['death_30d'], axis = 1).copy()  # Features (drop the target column)\n",
    "\n",
    "X_eval_mortality = X_eval_mortality[selected_features_icu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d66f8-e77c-43cc-86af-e6168aea13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_mortality = standardized_eval_df ['death_30d'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c48f9-98dd-4c36-b042-45acde86c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prevalence in preparation for DCA\n",
    "y_eval_mortality = np.array(y_eval_mortality)\n",
    "\n",
    "# Calculate the positive rate\n",
    "prevalence = np.mean(y_eval_mortality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a828bb-8005-4ea3-a3e0-3a146564e3a0",
   "metadata": {},
   "source": [
    "### AUC computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65636d8c-1655-49f1-833b-738efa0c2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities on the validation set\n",
    "y_eval_mortality_pred_proba = best_lasso_icu.predict_proba(X_eval_mortality)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score_mortality = roc_auc_score(y_eval_mortality, y_eval_mortality_pred_proba)\n",
    "\n",
    "print(\"AUC Score: \", auc_score_mortality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c553e2e-2ce4-4b8e-9acf-40a35e012096",
   "metadata": {},
   "source": [
    "### Calibration in the large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f31ec-bafe-40d9-8d9d-46987cadb717",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_in_the_large = np.mean(y_eval_mortality_pred_proba) - np.mean(y_eval_mortality)\n",
    "print(\"Calibration in the Large: \", calibration_in_the_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd38cf3-b7af-4d3f-bf2a-d1dc150f8735",
   "metadata": {},
   "source": [
    "### Calibration intercept and slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ffa61-17bd-4eb1-b31d-8f0b4dba1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_eval_icu is the observed outcome (0 or 1)\n",
    "# and y_eval_icu_pred_proba is the predicted probability from your model\n",
    "\n",
    "# Convert predicted probabilities to log-odds\n",
    "log_odds = np.log(y_eval_mortality_pred_proba / (1 - y_eval_mortality_pred_proba))\n",
    "\n",
    "# Add a constant term for the intercept in the logistic regression model\n",
    "X_log_odds = sm.add_constant(log_odds)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y_eval_mortality, X_log_odds).fit(disp=0)  # disp=0 suppresses output during fitting\n",
    "\n",
    "# Extract the intercept and slope\n",
    "calibration_intercept = model.params[0]  # Intercept\n",
    "calibration_slope = model.params[1]      # Slope\n",
    "\n",
    "print(\"Calibration Intercept: \", calibration_intercept)\n",
    "print(\"Calibration Slope: \", calibration_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da58e7-ff3b-479f-b504-e0fafa7fcf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    # Predict probabilities on the validation set\n",
    "    y_eval_mortality_pred_proba = best_lasso_icu.predict_proba(X_eval_mortality)[:, 1]  # Probabilities for the positive class\n",
    "    \n",
    "    # To calculate calibration intercept and slope:\n",
    "    # 1. Take the logit (log-odds) of the predicted probabilities\n",
    "    logit_pred_proba = np.log(y_eval_mortality_pred_proba / (1 - y_eval_mortality_pred_proba))\n",
    "    \n",
    "    # 2. Reshape and standardize the logit predictions\n",
    "    logit_pred_proba = logit_pred_proba.reshape(-1, 1)\n",
    "    scaler_cali = StandardScaler()\n",
    "    logit_pred_proba_scaled = scaler_cali.fit_transform(logit_pred_proba)\n",
    "    \n",
    "    # 3. Fit a logistic regression model to assess calibration\n",
    "    calibration_model = LogisticRegression(fit_intercept=True)\n",
    "    calibration_model.fit(logit_pred_proba_scaled, y_eval_mortality)\n",
    "    \n",
    "    # 4. Extract calibration intercept and slope\n",
    "    calibration_intercept = calibration_model.intercept_[0]\n",
    "    calibration_slope = calibration_model.coef_[0][0]\n",
    "    \n",
    "    print(\"Calibration Intercept: \", calibration_intercept)\n",
    "    print(\"Calibration Slope: \", calibration_slope)\n",
    "    \n",
    "    # Convert intercept back to probability\n",
    "    original_intercept_probability = 1 / (1 + np.exp(-calibration_intercept))\n",
    "    print(\"Calibration Intercept (Probability Scale): \", original_intercept_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a4f38-f09a-4ede-af89-eed874315bc7",
   "metadata": {},
   "source": [
    "### Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacabdfc-b5ce-4ce7-bc25-c0c8cce2f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_eval_mortality, y_eval_mortality_pred_proba, n_bins = 100)\n",
    "\n",
    "# Apply LOESS smoothing\n",
    "loess_fraction = 0.8  # Adjust this value to change the degree of smoothing\n",
    "smoothed_values = lowess(prob_true, prob_pred, frac=loess_fraction)\n",
    "\n",
    "# Extract smoothed x and y values\n",
    "smoothed_x = smoothed_values[:, 0]\n",
    "smoothed_y = smoothed_values[:, 1]\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve', color='blue')\n",
    "plt.plot(smoothed_x, smoothed_y, label = 'LOESS Smoothed', color = 'red', linewidth = 0.8)\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\", color = 'grey', linewidth = 0.8)  # Reference line for perfect calibration\n",
    "\n",
    "# Set limits and ensure equal unit lengths on both axes\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable = 'box')  # This ensures equal scaling of both axes\n",
    "\n",
    "plt.xlabel('Predicted risk', fontsize = 14)\n",
    "plt.ylabel('Observed risk', fontsize = 14)\n",
    "plt.xticks(fontsize = 12)  # Adjust font size for x-axis tick labels\n",
    "plt.yticks(fontsize = 12)  # Adjust font size for y-axis tick labels\n",
    "#plt.title('Calibration Plot', fontsize=16)\n",
    "#plt.legend(loc=\"best\", fontsize = 12)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(False)\n",
    "plt.savefig(r'T:\\Projects\\NAPKON\\projects\\CROSS_mortality\\python\\results\\figures\\xgboost_mortality\\calibration_plot_12FeaturesbyFscore.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70337e2a-092d-49d2-8fb6-e0cf410fe71e",
   "metadata": {},
   "source": [
    "### Brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a322a0-d61c-4fd9-95ed-4fa74aaaef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for the positive class\n",
    "y_eval_mortality_pred_proba = best_lasso_icu.predict_proba(X_eval_mortality)[:, 1]\n",
    "\n",
    "# Calculate Brier score\n",
    "brier_score = brier_score_loss(y_eval_mortality, y_eval_mortality_pred_proba)\n",
    "\n",
    "print(f\"Brier Score: {brier_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191c86f-9986-4035-b776-c209ed75fe35",
   "metadata": {},
   "source": [
    "### Decision curve analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c83ecf-6896-41e2-8921-7c581f740a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `y_eval_icu` (ground truth) and `y_eval_icu_pred_proba` (predicted probabilities) are available\n",
    "dat_all = pd.DataFrame({'death_30d': y_eval_mortality, 'der_pred_cross': y_eval_mortality_pred_proba})\n",
    "\n",
    "prevalence = prevalence\n",
    "\n",
    "# Function to calculate net benefit for decision curve analysis\n",
    "def decision_curve_analysis(data, threshold_probs, prevalence = prevalence):\n",
    "    net_benefits = []\n",
    "    for threshold in threshold_probs:\n",
    "        tp = np.sum((data['der_pred_cross'] >= threshold) & (data['death_30d'] == 1))\n",
    "        fp = np.sum((data['der_pred_cross'] >= threshold) & (data['death_30d'] == 0))\n",
    "        nb = tp / len(data) - (fp / len(data)) * (threshold / (1 - threshold))\n",
    "        net_benefits.append(nb)\n",
    "    return pd.DataFrame({'threshold': threshold_probs, 'net_benefit': net_benefits})\n",
    "\n",
    "# Function to calculate the net benefit for the \"Treat All\" strategy\n",
    "def treat_all_line(threshold_probs, prevalence):\n",
    "    return prevalence - (1 - prevalence) * (threshold_probs / (1 - threshold_probs))\n",
    "\n",
    "# Define threshold probabilities for DCA\n",
    "threshold_probs = np.linspace(0.01, 1.0, 100)\n",
    "\n",
    "# Perform decision curve analysis\n",
    "df_plot = decision_curve_analysis(dat_all, threshold_probs, prevalence)\n",
    "\n",
    "# Calculate the \"Treat All\" line using the correct formula\n",
    "df_plot['treat_all'] = treat_all_line(threshold_probs, prevalence)\n",
    "\n",
    "# Apply LOESS smoothing to net benefit\n",
    "loess_smoothed = lowess(df_plot['net_benefit'], df_plot['threshold'], frac=0.2)  # frac controls the amount of smoothing\n",
    "\n",
    "# Prepare smoothed results for plotting\n",
    "smoothed_df = pd.DataFrame(loess_smoothed, columns=['threshold', 'smoothed_net_benefit'])\n",
    "\n",
    "# Color and linetype mapping for the plot\n",
    "color_labels = {\n",
    "    'der_pred_cross': '#B22222',  # Red color for CROSS score\n",
    "    'Treat All': '#000000',        # Black color for Treat All\n",
    "    'Treat None': '#808080'        # Grey color for Treat None\n",
    "}\n",
    "linetype_labels = {\n",
    "    'der_pred_cross': 'solid',\n",
    "    'Treat All': 'solid',\n",
    "    'Treat None': 'solid'\n",
    "}\n",
    "legend_labels = {\n",
    "    'der_pred_cross': 'CROSS score',\n",
    "    'Treat All': 'Treat all',\n",
    "    'Treat None': 'Treat none'\n",
    "}\n",
    "\n",
    "# Plot the LOESS smoothed net benefit for CROSS score (DCA curve)\n",
    "sns.lineplot(data=smoothed_df, \n",
    "             x='threshold', \n",
    "             y='smoothed_net_benefit', \n",
    "             label=legend_labels['der_pred_cross'], \n",
    "             color=color_labels['der_pred_cross'], \n",
    "             linestyle=linetype_labels['der_pred_cross'], \n",
    "             linewidth=0.4)  \n",
    "\n",
    "# Plot the Treat None line (always at y = 0)\n",
    "plt.axhline(y=0, \n",
    "            color=color_labels['Treat None'], \n",
    "            linestyle='solid', \n",
    "            label=legend_labels['Treat None'], \n",
    "            linewidth=0.2)  \n",
    "\n",
    "# Plot the Treat All line (calculated as a slant line)\n",
    "sns.lineplot(x=threshold_probs, \n",
    "             y=df_plot['treat_all'], \n",
    "             label=legend_labels['Treat All'], \n",
    "             color=color_labels['Treat All'], \n",
    "             linestyle=linetype_labels['Treat All'], \n",
    "             linewidth=0.2)  \n",
    "\n",
    "# Customize plot\n",
    "plt.title(\"DCA for Multiple Models with LOESS Smoothing\")\n",
    "plt.xlabel(\"Threshold probability\")\n",
    "plt.ylabel(\"Net benefit\")\n",
    "plt.ylim(-0.3, 0.3)  # Adjust y-limits if necessary\n",
    "plt.legend(title=\"Models\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595abc4b-f3f2-411f-8906-a43161595a8c",
   "metadata": {},
   "source": [
    "## Evaluation for deterioration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5156943-770d-4621-b283-32379b5cb801",
   "metadata": {},
   "source": [
    "### Multiple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc8371-c379-474f-9e9d-ab8bae90b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target columns\n",
    "eval_df_deterioration = eval_df_cleaned.drop(['death_30d', 'icu_7d'], axis=1)\n",
    "\n",
    "# Define number of imputations and iterations\n",
    "n_imputations = 10\n",
    "max_iter = 10\n",
    "\n",
    "# Initialize an empty list to hold all imputed datasets\n",
    "imputed_eval_df = []\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_cols = ['age', 'num_comor', 'hr', 'bp_sys', 'bp_dia', 'rr', 'temp', 'spo2', 'wbc_abs', 'platelet_abs', 'urea', 'creatinine', 'crp', 'ldh']\n",
    "categorical_cols_deterioration = [col for col in categorical_cols if col not in ['death_30d', 'icu_7d']]\n",
    "\n",
    "# Store the target variable separately\n",
    "target_variable = eval_df_deterioration['deterioration'] if 'deterioration' in eval_df_deterioration.columns else None\n",
    "\n",
    "# Remove the target variable from categorical columns for imputation\n",
    "if target_variable is not None:\n",
    "    categorical_cols_deterioration.remove('deterioration')\n",
    "\n",
    "# Initialize IterativeImputer for continuous variables with PMM\n",
    "pmm_imputer = IterativeImputer(max_iter = max_iter, random_state = 123)\n",
    "\n",
    "# Initialize IterativeImputer for categorical variables with logistic regression\n",
    "logreg_imputer = IterativeImputer(max_iter = max_iter, estimator=LogisticRegression(max_iter = 1000), random_state = 123)\n",
    "\n",
    "# Perform multiple imputations\n",
    "for i in range(n_imputations):\n",
    "    # Fit and transform the continuous data\n",
    "    imputed_numerical = pmm_imputer.fit_transform(eval_df_deterioration[numerical_cols])\n",
    "    imputed_categorical = logreg_imputer.fit_transform(eval_df_deterioration[categorical_cols_deterioration])\n",
    "    \n",
    "    # Convert to DataFrame and store\n",
    "    imputed_numerical_df = pd.DataFrame(imputed_numerical, columns = numerical_cols)\n",
    "    imputed_categorical_df = pd.DataFrame(imputed_categorical, columns = categorical_cols_deterioration)\n",
    "    \n",
    "    # Combine the imputed numerical and categorical DataFrames\n",
    "    combined_imputed_df = pd.concat([imputed_numerical_df, imputed_categorical_df], axis = 1)\n",
    "    \n",
    "    # If the target variable exists, add it back to the combined DataFrame\n",
    "    if target_variable is not None:\n",
    "        combined_imputed_df['deterioration'] = target_variable.values\n",
    "    \n",
    "    # Append the combined DataFrame to the list\n",
    "    imputed_eval_df.append(combined_imputed_df)\n",
    "\n",
    "# Stack all imputed datasets into one DataFrame\n",
    "combined_imputed_eval_df = pd.concat(imputed_eval_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed63b2-4599-4b4e-9ece-9fe535cf9c01",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ecf97b-0e09-4f4f-9f35-cd41c9ea4469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_cols_deterioration.append('deterioration')\n",
    "\n",
    "# Apply the same StandardScaler (already fitted on dev_df) to eval_df\n",
    "scaled_numeric_eval_data = scaler.transform(combined_imputed_eval_df[numerical_cols])\n",
    "\n",
    "# Convert the scaled numeric data back to a DataFrame\n",
    "scaled_numeric_eval_df = pd.DataFrame(scaled_numeric_eval_data, columns = numerical_cols)\n",
    "\n",
    "# Recombine the standardized numeric columns with the original unchanged categorical columns in eval_df\n",
    "standardized_eval_df = pd.concat([scaled_numeric_eval_df.reset_index(drop=True), \n",
    "                                  combined_imputed_eval_df[categorical_cols_deterioration].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the standardized eval DataFrame\n",
    "print(standardized_eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bcb975-5cdf-405d-9213-ec5c8ad5222b",
   "metadata": {},
   "source": [
    "### Split the eval_df into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a8fae-95f7-4aa6-9ef7-646bb57a4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_deterioration = standardized_eval_df.drop(['deterioration'], axis = 1).copy()  # Features (drop the target column)\n",
    "\n",
    "X_eval_deterioration = X_eval_deterioration[selected_features_icu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b619a-01fc-4d3e-9b5f-a1e0a4219f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_deterioration = standardized_eval_df ['deterioration'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1dc44-0efa-484a-b805-583905ef75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prevalence in preparation for DCA\n",
    "y_eval_deterioration = np.array(y_eval_deterioration)\n",
    "\n",
    "# Calculate the positive rate\n",
    "prevalence = np.mean(y_eval_deterioration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62253072-ae8f-4a19-90bb-6795d087c738",
   "metadata": {},
   "source": [
    "### AUC computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec6864-93e2-44b7-89aa-c8b229b73b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities on the validation set\n",
    "y_eval_deterioration_pred_proba = best_lasso_icu.predict_proba(X_eval_deterioration)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score_deterioration = roc_auc_score(y_eval_deterioration, y_eval_deterioration_pred_proba)\n",
    "\n",
    "print(\"AUC Score: \", auc_score_deterioration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2b7c7-91be-47a8-b402-913a132cd7e8",
   "metadata": {},
   "source": [
    "### Calibration in the large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69f346-a691-491d-a1cc-8ea007ff62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_in_the_large = np.mean(y_eval_deterioration_pred_proba) - np.mean(y_eval_deterioration)\n",
    "print(\"Calibration in the Large: \", calibration_in_the_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd974c2f-052a-49e7-b23c-941ee32fa75f",
   "metadata": {},
   "source": [
    "### Calibration intercept and slope "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343d832-26d4-4952-9f6b-f6947fd34fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_eval_icu is the observed outcome (0 or 1)\n",
    "# and y_eval_icu_pred_proba is the predicted probability from your model\n",
    "\n",
    "# Convert predicted probabilities to log-odds\n",
    "log_odds = np.log(y_eval_deterioration_pred_proba / (1 - y_eval_deterioration_pred_proba))\n",
    "\n",
    "# Add a constant term for the intercept in the logistic regression model\n",
    "X_log_odds = sm.add_constant(log_odds)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y_eval_deterioration, X_log_odds).fit(disp=0)  # disp=0 suppresses output during fitting\n",
    "\n",
    "# Extract the intercept and slope\n",
    "calibration_intercept = model.params[0]  # Intercept\n",
    "calibration_slope = model.params[1]      # Slope\n",
    "\n",
    "print(\"Calibration Intercept: \", calibration_intercept)\n",
    "print(\"Calibration Slope: \", calibration_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54005a-efbe-4a3b-8146-04965c6df546",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    # Predict probabilities on the validation set\n",
    "    y_eval_deterioration_pred_proba = best_lasso_icu.predict_proba(X_eval_deterioration)[:, 1]  # Probabilities for the positive class\n",
    "    \n",
    "    # To calculate calibration intercept and slope:\n",
    "    # 1. Take the logit (log-odds) of the predicted probabilities\n",
    "    logit_pred_proba = np.log(y_eval_deterioration_pred_proba / (1 - y_eval_deterioration_pred_proba))\n",
    "    \n",
    "    # 2. Reshape and standardize the logit predictions\n",
    "    logit_pred_proba = logit_pred_proba.reshape(-1, 1)\n",
    "    scaler_cali = StandardScaler()\n",
    "    logit_pred_proba_scaled = scaler_cali.fit_transform(logit_pred_proba)\n",
    "    \n",
    "    # 3. Fit a logistic regression model to assess calibration\n",
    "    calibration_model = LogisticRegression(fit_intercept=True)\n",
    "    calibration_model.fit(logit_pred_proba_scaled, y_eval_deterioration)\n",
    "    \n",
    "    # 4. Extract calibration intercept and slope\n",
    "    calibration_intercept = calibration_model.intercept_[0]\n",
    "    calibration_slope = calibration_model.coef_[0][0]\n",
    "    \n",
    "    print(\"Calibration Intercept: \", calibration_intercept)\n",
    "    print(\"Calibration Slope: \", calibration_slope)\n",
    "    \n",
    "    # Convert intercept back to probability\n",
    "    original_intercept_probability = 1 / (1 + np.exp(-calibration_intercept))\n",
    "    print(\"Calibration Intercept (Probability Scale): \", original_intercept_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a92c6c-32e9-4c30-a4c6-57eea1d2b73b",
   "metadata": {},
   "source": [
    "### Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc1072-d27d-449c-baba-2b3022d7c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_eval_deterioration, y_eval_deterioration_pred_proba, n_bins = 100)\n",
    "\n",
    "# Apply LOESS smoothing\n",
    "loess_fraction = 0.8  # Adjust this value to change the degree of smoothing\n",
    "smoothed_values = lowess(prob_true, prob_pred, frac=loess_fraction)\n",
    "\n",
    "# Extract smoothed x and y values\n",
    "smoothed_x = smoothed_values[:, 0]\n",
    "smoothed_y = smoothed_values[:, 1]\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve', color='blue')\n",
    "plt.plot(smoothed_x, smoothed_y, label = 'LOESS Smoothed', color = 'red', linewidth = 0.8)\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\", color = 'grey', linewidth = 0.8)  # Reference line for perfect calibration\n",
    "\n",
    "# Set limits and ensure equal unit lengths on both axes\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable = 'box')  # This ensures equal scaling of both axes\n",
    "\n",
    "plt.xlabel('Predicted risk', fontsize = 14)\n",
    "plt.ylabel('Observed risk', fontsize = 14)\n",
    "plt.xticks(fontsize = 12)  # Adjust font size for x-axis tick labels\n",
    "plt.yticks(fontsize = 12)  # Adjust font size for y-axis tick labels\n",
    "#plt.title('Calibration Plot', fontsize=16)\n",
    "#plt.legend(loc=\"best\", fontsize = 12)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(False)\n",
    "plt.savefig(r'T:\\Projects\\NAPKON\\projects\\CROSS_mortality\\python\\results\\figures\\xgboost_mortality\\calibration_plot_12FeaturesbyFscore.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36ec04-e149-4194-b017-89d0385172ff",
   "metadata": {},
   "source": [
    "### Brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe22927-40e1-408a-bc09-c647f6a69278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for the positive class\n",
    "y_eval_deterioration_pred_proba = best_lasso_icu.predict_proba(X_eval_deterioration)[:, 1]\n",
    "\n",
    "# Calculate Brier score\n",
    "brier_score = brier_score_loss(y_eval_deterioration, y_eval_deterioration_pred_proba)\n",
    "\n",
    "print(f\"Brier Score: {brier_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad22d8bd-e4b1-4bb0-a23d-214bddde3236",
   "metadata": {},
   "source": [
    "### Decision curve analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ccd7d-d6f0-40bc-819d-47180daab95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `y_eval_icu` (ground truth) and `y_eval_icu_pred_proba` (predicted probabilities) are available\n",
    "dat_all = pd.DataFrame({'deterioration': y_eval_deterioration, 'der_pred_cross': y_eval_deterioration_pred_proba})\n",
    "\n",
    "prevalence = prevalence\n",
    "\n",
    "# Function to calculate net benefit for decision curve analysis\n",
    "def decision_curve_analysis(data, threshold_probs, prevalence = prevalence):\n",
    "    net_benefits = []\n",
    "    for threshold in threshold_probs:\n",
    "        tp = np.sum((data['der_pred_cross'] >= threshold) & (data['deterioration'] == 1))\n",
    "        fp = np.sum((data['der_pred_cross'] >= threshold) & (data['deterioration'] == 0))\n",
    "        nb = tp / len(data) - (fp / len(data)) * (threshold / (1 - threshold))\n",
    "        net_benefits.append(nb)\n",
    "    return pd.DataFrame({'threshold': threshold_probs, 'net_benefit': net_benefits})\n",
    "\n",
    "# Function to calculate the net benefit for the \"Treat All\" strategy\n",
    "def treat_all_line(threshold_probs, prevalence):\n",
    "    return prevalence - (1 - prevalence) * (threshold_probs / (1 - threshold_probs))\n",
    "\n",
    "# Define threshold probabilities for DCA\n",
    "threshold_probs = np.linspace(0.01, 1.0, 100)\n",
    "\n",
    "# Perform decision curve analysis\n",
    "df_plot = decision_curve_analysis(dat_all, threshold_probs, prevalence)\n",
    "\n",
    "# Calculate the \"Treat All\" line using the correct formula\n",
    "df_plot['treat_all'] = treat_all_line(threshold_probs, prevalence)\n",
    "\n",
    "# Apply LOESS smoothing to net benefit\n",
    "loess_smoothed = lowess(df_plot['net_benefit'], df_plot['threshold'], frac=0.2)  # frac controls the amount of smoothing\n",
    "\n",
    "# Prepare smoothed results for plotting\n",
    "smoothed_df = pd.DataFrame(loess_smoothed, columns=['threshold', 'smoothed_net_benefit'])\n",
    "\n",
    "# Color and linetype mapping for the plot\n",
    "color_labels = {\n",
    "    'der_pred_cross': '#B22222',  # Red color for CROSS score\n",
    "    'Treat All': '#000000',        # Black color for Treat All\n",
    "    'Treat None': '#808080'        # Grey color for Treat None\n",
    "}\n",
    "linetype_labels = {\n",
    "    'der_pred_cross': 'solid',\n",
    "    'Treat All': 'solid',\n",
    "    'Treat None': 'solid'\n",
    "}\n",
    "legend_labels = {\n",
    "    'der_pred_cross': 'CROSS score',\n",
    "    'Treat All': 'Treat all',\n",
    "    'Treat None': 'Treat none'\n",
    "}\n",
    "\n",
    "# Plot the LOESS smoothed net benefit for CROSS score (DCA curve)\n",
    "sns.lineplot(data=smoothed_df, \n",
    "             x='threshold', \n",
    "             y='smoothed_net_benefit', \n",
    "             label=legend_labels['der_pred_cross'], \n",
    "             color=color_labels['der_pred_cross'], \n",
    "             linestyle=linetype_labels['der_pred_cross'], \n",
    "             linewidth=0.4)  \n",
    "\n",
    "# Plot the Treat None line (always at y = 0)\n",
    "plt.axhline(y=0, \n",
    "            color=color_labels['Treat None'], \n",
    "            linestyle='solid', \n",
    "            label=legend_labels['Treat None'], \n",
    "            linewidth=0.2)  \n",
    "\n",
    "# Plot the Treat All line (calculated as a slant line)\n",
    "sns.lineplot(x=threshold_probs, \n",
    "             y=df_plot['treat_all'], \n",
    "             label=legend_labels['Treat All'], \n",
    "             color=color_labels['Treat All'], \n",
    "             linestyle=linetype_labels['Treat All'], \n",
    "             linewidth=0.2)  \n",
    "\n",
    "# Customize plot\n",
    "plt.title(\"DCA for Multiple Models with LOESS Smoothing\")\n",
    "plt.xlabel(\"Threshold probability\")\n",
    "plt.ylabel(\"Net benefit\")\n",
    "plt.ylim(-0.1, 0.3)  # Adjust y-limits if necessary\n",
    "plt.legend(title=\"Models\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
